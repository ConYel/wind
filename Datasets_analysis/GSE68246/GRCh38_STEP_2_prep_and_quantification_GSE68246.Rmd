---
title: "wind: wORKFLOW FOR PiRNAs AnD BEYONd"
subtitle: "Computational workflow for the preprocessing of the GSE68246 dataset regarding Human Breast MCF-7 Cell Line with Cancer Stem Cell Properties"
author: "Constantinos Yeles (Konstantinos Geles)"
date: "`r format(Sys.time(), '%a_%b_%d_%Y')`"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
  html_document:
    toc: yes
    toc_depth: 3
    theme: paper 
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```
## The Data set

We will work on a public dataset with GEO accession number: [GSE68246](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE68246),
that it has been used in the publications: __[Phenotypic and microRNA transcriptomic profiling of the MDA-MB-231 spheroid-enriched CSCs with comparison of MCF-7 microRNA profiling dataset](https://pubmed.ncbi.nlm.nih.gov/28717596/)__ and __[MiRNA Transcriptome Profiling of Spheroid-Enriched Cells with Cancer Stem Cell Properties in Human Breast MCF-7 Cell Line](https://pubmed.ncbi.nlm.nih.gov/27019627/)__

## Data aqcuisition and preprocessing  

### i. Downloading the samples

We will use the [fastq-dl](https://github.com/rpetit3/fastq-dl) tool to download
the samples from the European Nucleotide Archive

```{bash download samples}
docker run --rm -ti -v $(pwd):/home/my_data  congelos/sncrna_workflow

# run the script to download the fastqs
fastq-dl --cpus 8 --prefix "PRJNA282131" \
--group_by_experiment  --outdir my_data/Datasets_analysis/GSE68246/downloaded_samples PRJNA282131 ENA 

```

### ii. Preprocessing of the samples
We perform quality control(QC) on the fastq files to get basic information about the samples.
We work with the __[Fastqc](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)__ tool to perform QC.

```{bash preprocessing}
ANALYSIS_FOLDER="my_data/Datasets_analysis/GSE68246"

mkdir "${ANALYSIS_FOLDER}"/qc_before_trim "${ANALYSIS_FOLDER}"/qc_after_trim \
"${ANALYSIS_FOLDER}"/quants  "${ANALYSIS_FOLDER}"/star

'fastqc' --threads 6 --outdir="${ANALYSIS_FOLDER}"/qc_before_trim \
"${ANALYSIS_FOLDER}"/downloaded_samples/*fastq.gz 

for file in "${ANALYSIS_FOLDER}"/downloaded_samples/*.fastq.gz;  
do 
./spar_prepare/smrna_adapter_cut.sh $file 8; 
done

'fastqc' --threads 6 --outdir="${ANALYSIS_FOLDER}"/qc_after_trim \
"${ANALYSIS_FOLDER}"/downloaded_samples/*.trimmed.fastq.gz

for file in my_data/downloaded_SRA/GSE_samples/*.fastq.gz; 
do ./spar_prepare/smrna_adapter_cut.sh $file 6; 
done

mkdir my_data/downloaded_SRA/GSE_samples/qc_after

'fastqc' --threads 6 --outdir=my_data/qc_after/ my_data/downloaded_SRA/GSE_samples/*.trimmed.fastq.gz

exit
```
## 2. Alignment and Quantification
### i. Transcript abundances with __[Salmon](https://github.com/COMBINE-lab/salmon)__

We will use a public docker image to run salmon

```{bash salmon}
# run the docker
docker run --rm -it -v $(pwd):/home/my_data combinelab/salmon

ANALYSIS_FOLDER="my_data/Datasets_analysis/GSE68246"

# run the samples

for fn in "${ANALYSIS_FOLDER}"/downloaded_samples/*.trimmed.fastq.gz;   
do  samp=`basename ${fn}`;   
regex="${samp%%.trimmed.fastq.gz}";   
echo "Processing sample ${samp} start: $(date)";   
salmon quant -i my_data/human_data/indexes/GRCh38_v34_spike_ins_salmon  \
-l A -r ${fn} --seqBias --gcBias --numBootstraps 100  -p 12 \
--validateMappings --writeMappings="${ANALYSIS_FOLDER}/quants/${regex}.sam" \
-o "${ANALYSIS_FOLDER}/quants/${regex}_quant"; 
echo "end:$(date)";
done
exit

docker run --rm -ti -v $(pwd):/home/my_data  congelos/sncrna_workflow
#save as bam files
for file in "${ANALYSIS_FOLDER}"/quants/*.sam;
do 
regex="${file%%.sam}";
echo "Processing sample ${regex} start: $(date)"; 
echo samtools view -O bam -o ${regex}.bam -@ 8 ${file};
echo "end:$(date)";
done
# remove all .sam files
rm ${ANALYSIS_FOLDER}/quants/*.sam
```
### ii. Alignment with STAR
We use the __[STAR](https://github.com/alexdobin/STAR)__ aligner and then
perform quantification with featureCounts of __[Rsubread](https://www.bioconductor.org/packages/release/bioc/html/Rsubread.html)__ package.

```{bash STAR}
for file in  "${ANALYSIS_FOLDER}"/downloaded_samples/*.trimmed.fastq.gz; 
do 
samp=`basename ${file}`; 
regex="${samp%%.trimmed.fastq.gz}"; 
echo "Processing sample ${samp} start: $(date)"; 
STAR --genomeDir my_data/human_data/indexes/GRCh38_v34_spike_ins_STAR \
--genomeLoad LoadAndKeep --readFilesIn ${file} --readFilesCommand zcat \
--runThreadN 12 --alignIntronMax 1 --outSAMattributes NH HI NM MD \
--outFilterMultimapNmax 100 --outSAMtype BAM SortedByCoordinate \
--limitBAMsortRAM 40000000000 --outReadsUnmapped Fastx \
--outFilterMismatchNmax 1 --outFilterMatchNmin 14 \
--outFileNamePrefix "${ANALYSIS_FOLDER}/star/${regex}_align/${regex}_";  
echo "end:$(date)";
done

exit
```
Next, we run a docker image which includes various R packages that
will be used in the downstream analysis following featurecounts
for the exploratory data analysis of piRNA data

### R docker
```{bash docker for R}
docker run --rm -v $(pwd):/home/0 -p 8787:8787 -e PASSWORD=12345 -e USER=$UID congelos/rocker_tidyverse_plus_de_pckages
```

From here on we work on Rstudio using a browser. 
we input http://localhost:8787/ on browser, 0 for username and 12345 for password.

### iv. __[featureCounts](http://subread.sourceforge.net/)__
```{r featureCounts}
library(Rsubread)
library(tidyverse)

ANALYSIS_FOLDER <- file.path("Datasets_analysis", "GSE68246")
  
list.BAM <- list.files(path = file.path(ANALYSIS_FOLDER, "star"), 
                       pattern = ".bam$", 
                       recursive = TRUE, 
                       full.names = TRUE)

path_gtf <- file.path("human_data","sncRNA_spike_ins_piRNBnk_RNACent_GRCh38_v34.gtf")
todate <- format(Sys.time(), "%d_%b_%Y")

fc <- featureCounts(files = list.BAM,
                    annot.ext =  path_gtf,
                    isGTFAnnotationFile = TRUE,
                    GTF.featureType = "exon",
                    GTF.attrType.extra = c("gene_type", "sRNA_id", "seq_RNA"),
                    nthreads = 13,
                    useMetaFeatures = TRUE,
                    allowMultiOverlap = TRUE,
                    minOverlap = 10,
                    largestOverlap = TRUE,
                    fraction = TRUE,
                    strandSpecific = 0,
                    verbose = TRUE,
                    reportReads = "BAM",
                    reportReadsPath = file.path(ANALYSIS_FOLDER, "star")) 

fc %>% 
  write_rds(file = str_glue(file.path(ANALYSIS_FOLDER, "feature_counts_"), 
                            "{todate}.rds"))
```

Next we will follow the instructions in STEP_3_Exploratory_Data_Analysis.Rmd 

