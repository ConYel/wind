---
title: "wind: wORKFLOW FOR PiRNAs AnD BEYONd"
subtitle: "Computational workflow for Data Exploration resulted from smallRNA-seq of testis and COLO205 samples"
author: "Constantinos Yeles (Konstantinos Geles)"
date: "`r format(Sys.time(), '%a %b %d %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    theme: paper 
  pdf_document:
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```
Following the step 2 we are working again on the docker of Rstudio loaded before.
## 1. Load libraries

```{r load libraries}
suppressPackageStartupMessages({
  library('tidyverse') 
  library('data.table')
  library('plyranges')
  library('tximport')
  library('edgeR')
  library('NOISeq')
  library('rafalib')
  library('pheatmap')
  library('RColorBrewer')
  library('jsonlite')
})
```
## 2. Directory generation for the resulted files
### i. Add date

Used as an identifier for the folder 

```{r todate_of_analysis}
todate <- format(Sys.time(), "%d_%b_%Y")
```
### ii. Make the directory for the results of the exploratory data analysis

```{r make dirs}
my_basename <- file.path("Datasets_analysis", "Testis_COLO205") ## INPUT name of the main folder 
my_exp <- "spike_ins_COLO205_Testis" ## INPUT name of the analysis
genome_input <- "GRCh38" ## INPUT genome version here
my_tools <- c("salmon","featureCounts")
dat_path <- file.path(my_basename, str_glue("EDA_{my_exp}_{genome_input}_{todate}"),
                      my_tools)
dat_path %>% map(~dir.create(., recursive = TRUE))
```
## 3. Make or import the targets file.

If you have used the [fastq-dl](https://github.com/rpetit3/fastq-dl) tool to download the samples from the European Nucleotide Archive then in the folder you have downloaded them should be also json file(s) that can be imported.
Otherwise you have to make them from scratch.
The targets file has to have at least three columns with the column names: "sample_name","group","batch"

```{r targets file}
## import the json files in a list and collapse them
## here we change also the batch levels as the samples are from two different cell lines / tissues
targets_file <- file.path(my_basename,"downloaded_samples") %>% 
  list.files( pattern = ".json", recursive = TRUE, full.names = TRUE) %>% 
  map(~jsonlite::fromJSON(.)) %>% 
  bind_rows() %>% 
  as_tibble() %>% 
  select(read_count, run_accession, #select only the columns with basic info
         sample_title, study_accession) %>% 
  mutate(group = sample_title %>% str_remove("_[:digit:]$"), 
         group = group %>% str_remove("_NT$"),
         cells = case_when(
           str_detect(group, "COLO205") ~ "COLO205",
           str_detect(group, "Testis|testis") ~ "Testis"
         ),
         batch = sample_title %>% str_remove(".+(?=[:digit:]$)") %>% as.numeric(),
         batch = case_when(
           str_detect(cells, "Testis|testis") ~ batch +4,
           TRUE ~ batch
         ),
         batch = as_factor(batch),
         read_count = as.integer(read_count),
         across(.cols = where(is.character), as_factor)) %>% 
  dplyr::rename(sample_name = sample_title)

targets_file$group %>% levels()

# remove last testis sample in order to have 3 non treated testis samples.
targets_file <- targets_file %>% filter(sample_name != "Non_treated_Testis_4")

targets_file <- targets_file %>% mutate(
  across(where(is.factor), droplevels)
)

```
## 4. Import the salmon files

```{r import salmon}
# load salmon files----
files_salm <- list.files(path = my_basename, pattern = ".sf",
  recursive = TRUE, full.names = TRUE)

names(files_salm) <- files_salm %>% 
  str_remove(".quant.sf") %>% 
  basename() %>% 
  str_remove("_quant")

# keep only the samples treated and not treated replicates
files_salm <- files_salm[names(files_salm) %in% as.character(targets_file$run_accession)]

# tximport-------
txi <- tximport::tximport(files_salm, type = "salmon",
  txOut = TRUE, countsFromAbundance = "lengthScaledTPM")
```
## 5. Make a DGElist object for salmon

```{r DGElist salmon}
# DGElist
# from https://bioconductor.org/packages/release/bioc/vignettes/tximport/inst/doc/tximport.html
# we follow the instructions to import for edgeR 
cts <- txi$counts
normMat <- txi$length

# change the colnames of the salmon objects
identical(as.character(targets_file$run_accession),colnames(cts))
colnames(cts) <- targets_file$sample_name
colnames(normMat) <- targets_file$sample_name

# Obtaining per-observation scaling factors for length, adjusted to avoid
# changing the magnitude of the counts
normMat <- normMat/exp(rowMeans(log(normMat)))
normCts <- cts/normMat

# Computing effective library sizes from scaled counts, to account for
# composition biases between samples
eff.lib <- calcNormFactors(normCts) * colSums(normCts)

# Combining effective library sizes with the length factors, and calculating
# offsets for a log-link GLM
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
dgl_salmon <- DGEList(cts, samples = targets_file) %>% 
  scaleOffset(normMat) %>% 
  write_rds(file.path(dat_path[1],"dgl_edgeR_salmon.rds"))
# remove objects.
rm(cts, normCts, normMat, txi)
```
## 6. Import the featureCounts object and make a DGElist object

```{r DGElist FeatureCounts}
# load the rds from featureCounts----
# INPUT rds featureCOunts
fc <- list.files(path = my_basename,
                 pattern = ".+counts.+.rds", 
                 full.names = TRUE) %>% 
  read_rds()

# keep only the samples treated and not treated replicates-----
fc$counts <- fc$counts[ , str_remove(colnames(fc$counts),pattern = "_Ali.+") %in% as.character(targets_file$run_accession)]
colnames(fc$counts) <- as.character(targets_file$sample_name)

fc$stat <- fc$stat[ , str_remove(colnames(fc$stat),pattern = "_Ali.+") %in% c("Status",as.character(targets_file$run_accession))] 
colnames(fc$stat) <-c("Status", as.character(targets_file$sample_name))

# write the matrix for the analysis, annotation stats-----
fc$counts %>% 
  as_tibble(rownames = "sRNA") %>% 
  write_tsv(file.path(dat_path[2], "raw_reads_fc.txt"))

fc$annotation %>% 
  as_tibble() %>% 
  write_tsv(file.path(dat_path[2],"annotation_fc.txt"))

fc$stat %>% 
  as_tibble() %>% 
  write_tsv(file.path(dat_path[2],"stats_fc.txt"))

dgl_fc <- DGEList(counts = fc$counts,
               samples = targets_file,
               lib.size = colSums(fc$counts),
               norm.factors = rep(1,ncol(fc$counts)))

# give colours to samples ----
pal1 <- tibble(value = c('#e41a1c','#377eb8',
                         '#4daf4a','#984ea3',
                         '#ff7f00','#ffff33',
                         '#a65628','#f781bf')) %>%
  dplyr::slice(1:length(levels(as_factor(targets_file$group)))) %>%
  mutate(
    group = as_factor(levels(as_factor(targets_file$group))))

dgl_fc$colours <- as_factor(inner_join(dgl_fc$samples, pal1,by= "group")$value)

# remove objects ----
rm(pal1)
```
## 7. Create biodetection plot with NOISeq

```{r biodetection plot}
mybiotypes <- fc$annotation %>% 
  mutate(gene_type = gene_type %>% str_remove(";.+")) %>% 
  select(GeneID,gene_type) %>% 
  column_to_rownames("GeneID")

function_Noiseq_plots <- function(exp_data, plot_path){
  mydata <- NOISeq::readData(data = exp_data, 
  factors = as.data.frame(targets_file),
  biotype = mybiotypes)
  mybiodetection <- dat(mydata, k = 0, type = "biodetection")
  pdf(file.path(plot_path, str_glue("NOISeq_biodetection_{todate}_{basename(plot_path)}.pdf")))
  seq(ncol(exp_data)) %>% map(~explo.plot(mybiodetection, samples = .x),plottype = "boxplot")
  dev.off()
  mycountsbio <- dat(mydata, factor = NULL, type = "countsbio")
  pdf(file.path(plot_path, str_glue("NOISeq_countsbio_{todate}_{basename(plot_path)}.pdf")))
  seq(ncol(exp_data)) %>% map(~explo.plot(mycountsbio, 
    samples = .x ,plottype = "boxplot"))
  dev.off()
}

list( "salmon" = dgl_salmon$counts, "fc" = fc$counts) %>% 
  map2(.y = dat_path, ~function_Noiseq_plots(.x,.y))
```
## 8. Create the design matrix

```{r design matrix}
design <- model.matrix(~0 + targets_file$group)
colnames(design) <- colnames(design) %>% 
  str_remove("targets_file\\$group") 
rownames(design) <- targets_file$sample_name
design_2 <- model.matrix(~0 + targets_file$group + targets_file$cells + targets_file$batch)
colnames(design_2) <- colnames(design_2) %>% 
  str_remove("targets_file\\$group") %>% 
  str_remove("targets_file\\$batch") %>% 
  str_remove("targets_file\\$cells")
rownames(design_2) <- targets_file$sample_name
```
## 9. Perform various Filtering Methods: EdgeR, NOIseq

```{r, Filtering}
function_filtering <- function(dgl_data, data_path){
  # filtering with NOISEq  -----
  noifil <- list("cpm" = 1L, "Prop" = 3L) %>%
    map(~NOISeq::filtered.data(dgl_data$counts,
      factor = dgl_data$samples$group,
      norm = FALSE,
      method = .x, cv.cutoff = 100, cpm = 1)
  )
  
  noifil %>% 
    names %>% 
    map( ~ dgl_data[rownames(dgl_data$counts) %in%
      rownames(noifil[.x]),,keep.lib.sizes = FALSE] %>% 
        write_rds(file.path(data_path, str_glue("dgl_{.x}_filt_{basename(data_path)}.rds")))
      )
  # filter with EdgeR ----
  keep.exprs <- filterByExpr.DGEList(dgl_data, design = design)
  keep.exprs_2 <- filterByExpr.DGEList(dgl_data, design = design_2)
  dgl_filt <- dgl_data[keep.exprs,,keep.lib.sizes=FALSE] %>% 
    write_rds(file.path(data_path, str_glue("dgl_edger_filt_nobatch_{basename(data_path)}.rds")))
  dgl_filt_2 <- dgl_data[keep.exprs_2,,keep.lib.sizes=FALSE] %>% 
    write_rds(file.path(data_path,str_glue("dgl_edger_filt_batch_{basename(data_path)}.rds")))
  
  # objects for the creation of filtering info table
  features_NOIS <- map(noifil, ~ .x %>%
      rownames() %>%
      enframe(name = NULL)) 
  features_edgeR <- map(list(dgl_filt, dgl_filt_2) , ~ .x %>%
      rownames() %>%
      enframe(name = NULL)) %>% 
    set_names("no_batch", "batch")
  
  common_edgeR_nobatch <- map2(features_edgeR[1], features_NOIS, ~ .x %>%
      inner_join(.y))
  common_edgeR_batch <- map2(features_edgeR[2], features_NOIS,  ~ .x %>%
      inner_join(.y))
  
  filter_info <- tibble(
    "features" = c("Starting_features:", "edgeR_nobatch_filter:",
      "edgeR_batch_filter:", 
      "NOISeq_1cpm_filter:",
      "common_with_edgeR_nobatch:", "common_with_edgeR_batch:",
      "NOISeq_Proportion_filter:", 
      "common_with_edgeR_nobatch:", "common_with_edgeR_batch:"
      ),
    "number_of_features" = c(nrow(dgl_data$counts), nrow(dgl_filt$counts),
      nrow(dgl_filt_2$counts),
      nrow(noifil[[1]]),
      nrow(common_edgeR_nobatch[[1]]),nrow(common_edgeR_batch[[1]]),
      nrow(noifil[[2]]),
      nrow(common_edgeR_nobatch[[2]]),nrow(common_edgeR_batch[[2]])
    )
  ) %>% 
    write_tsv(file.path(data_path, str_glue("filtering_info_{basename(data_path)}.txt")))
  dgl_filt
}

filtered_dgls <- list("salmon" = dgl_salmon, "fc" = dgl_fc) %>% 
  map2(.y = dat_path, ~function_filtering(.x,.y))
```
## 10. Histogram before and after filtering of data

```{r Histogram before and after}
function_hist <- function(dgl_data, dgl_fil_data, plot_path){
  AveLogCpm_Raw_Data <- aveLogCPM(dgl_data)
  AveLogCpm_Filtered_Data <-aveLogCPM(dgl_fil_data)
  pdf(file.path(plot_path, str_glue("histogram_plot_{todate}_{basename(plot_path)}.pdf")))
  hist(AveLogCpm_Raw_Data)
  hist(AveLogCpm_Filtered_Data)
dev.off()
}
list(list("salmon" = dgl_salmon, "fc" = dgl_fc), 
  filtered_dgls, dat_path) %>% 
   pmap(function_hist)
```
## 11. Normalization

```{r Normalization}
function_EDA_RLE <- function(data,name){EDASeq::plotRLE(data,
        col = as.character(dgl_fc$colours),
        outline=FALSE, las=3,
        ylab="Relative Log Expression", 
        cex.axis=1, cex.lab=1, main = str_glue("{name}"))
      legend("topright",
       legend= levels(as_factor(dgl_fc$samples$group)),
       fill = levels(as_factor(dgl_fc$colours)),
       bty="n",
       cex = 0.5, inset = c(.01,.01))
    }

function_norm <- function(dgl_fil_data, data_path){
  # edgeR ---- 
  norm_method <- list("none", "TMM", "TMMwsp", "RLE") %>% 
    set_names(.)
  edger_norm <- map(norm_method, ~calcNormFactors(dgl_fil_data, method = .x))
  # limma-voom  ----
  pdf(file.path(data_path,str_glue("voom_plots_{basename(data_path)}.pdf")))
  voom_norm <-  edger_norm[1:3] %>% 
    map2(.y = c("quantile", rep("none",2)),
      ~voom(.x, design = design_2,
        plot = TRUE, normalize.method = .y)) %>% 
    set_names("voom_Quantile","voom_TMM","voom_TMMwsp")
  dev.off()
  # limma-voom with quality weights ----
  pdf(file.path(data_path,str_glue("voom_quality_weights_plots_{basename(data_path)}.pdf")))
  voom_norm_QW <- edger_norm[1:3] %>% 
    map2(.y = c("quantile", rep("none",2)),
      ~voomWithQualityWeights(.x, design = design_2,
        plot = TRUE, normalize.method = .y)) %>% 
    set_names("voomQW_Quantile","voomQW_TMM","voomQW_TMMwsp")
  dev.off()
  # list of normalized data ----
  norm_list <- c(edger_norm %>% map(~cpm(.x, normalized.lib.sizes = TRUE)),
     list(
    "voom_Quantile" = 2^voom_norm[[1]]$E,
    "voom_TMM" = 2^voom_norm[[2]]$E,
    "voom_TMMwsp" = 2^voom_norm[[3]]$E,
    "voomQW_Quantile" = 2^voom_norm_QW[[1]]$E,
    "voomQW_TMM" = 2^voom_norm_QW[[2]]$E,
    "voomQW_TMMwsp" = 2^voom_norm_QW[[3]]$E))
  pdf(file.path(data_path, str_glue("RLE_plots_{basename(data_path)}.pdf")))
  norm_list %>%
    imap(~function_EDA_RLE(.x,.y))
  dev.off()
  norm_list[2:4] %>% imap(~.x %>% 
      as_tibble(rownames = "GeneIDs") %>% 
        write_tsv(file = file.path(data_path, str_glue("norm_cpm_{.y}_{basename(data_path)}.txt"))))
  c(edger_norm, voom_norm, voom_norm_QW)
}

norm_dgls <- filtered_dgls %>%
  map2(.y = dat_path, ~function_norm(.x, .y))
# save the list with all normalized values (edgeR and limma-voom)-----
  do_not_print <- map2( .x = norm_dgls, .y = dat_path, 
    ~write_rds(.x, file = file.path(.y, str_glue("list_norm_dgls_{basename(.y)}.rds"))))
```
## 12. Compare groups between FeatureCounts and salmon results

```{r cpm venn comparison}
function_comp_groups <- function(dgl_norm_data, tool){
 grouped_cpm  <- dgl_norm_data$TMM %>% 
    cpmByGroup.DGEList
   grouped_cpm %>% 
   as_tibble(rownames = "sncRNA") 
}

comp_FC_sal <- map2(norm_dgls, list("_salmon", "_fc"), ~function_comp_groups(.x,.y))

annot_tbl <- file.path("human_data","sncRNA_spike_ins_piRNBnk_RNACent_GRCh38_v34.gtf") %>% 
  read_gff2()

complete_biotypes_seqs <- annot_tbl %>% 
  as_tibble() %>% 
  distinct(gene_id, .keep_all = TRUE) %>% 
  select(!c(seqnames:strand,type:phase)) %>% 
  dplyr::rename("sncRNA" = gene_id)

salmon_FC_cpm_union_grouped <- comp_FC_sal %>% 
  bind_rows(.id = "method") %>% 
  pivot_longer(cols = !c(method,sncRNA)) %>% 
  pivot_wider(names_from = c(name, method),
              values_from = value) %>% 
  left_join(complete_biotypes_seqs) %>%
  select(sncRNA, gene_type, everything()) %>% 
  write_tsv(file.path(dirname(dat_path[1]), "salmon_FC_cpm_union_grouped.txt"))

# pick the top 100 expressed piRNAs between FC salmon and all groups -----
all_exprs_cpm_TMM <- dat_path %>% 
  map(~list.files(path = .x, 
                  recursive = TRUE ,
                  pattern = "norm_cpm_TMM_",
                  full.names = T)) %>% 
  vroom::vroom(id = "method") %>% 
  mutate(method = method %>% basename() %>% str_remove("norm_cpm_TMM_") %>% str_remove(".txt"))

salmon_FC_cpm_union_grouped_top <- salmon_FC_cpm_union_grouped %>% 
  filter(str_detect(gene_type, "piRNA")) %>% 
  arrange(across(.fns = dplyr::desc,
                 .cols = ends_with(c("salmon","fc")))) %>% 
  group_by(gene_type) %>% 
  slice_head(n = 100) 

all_exprs_cpm_TMM %>%
  filter(GeneIDs %in% salmon_FC_cpm_union_grouped_top$sncRNA) %>% 
  mutate(method = if_else(method == "featureCounts", 
                          true = "fc", 
                          false = "salmon")) %>%
  pivot_longer(cols = !c(method,GeneIDs)) %>% 
    unite(col = "sample",c(name, method)) %>%
  pivot_wider(names_from = "sample", 
              values_from = "value") %>% 
  write_tsv(file.path(dirname(dat_path[1]),"salmon_FC_cpm_union_top100.txt"))
```
## 13. Histograms of length per gene_type (sncRNA category)
### i. Make a table with the expressed gene_types per method

```{r stats_gene_types}
# import gtf and keep only the length of sncRNA
annot_tbl <- file.path("human_data","sncRNA_spike_ins_piRNBnk_RNACent_GRCh38_v34.gtf") %>% 
  read_gff2() %>% 
  as_tibble() %>%
  distinct(gene_id, .keep_all = T) %>% 
  select(gene_id, "length_w" = width, gene_type, seq_RNA)

# a function to prepare info for the table
function_prep_hist <- function(dgl_norm_data, annot_gtf){
  prep_hist <- annot_gtf %>% 
    filter(gene_id %in% rownames(dgl_norm_data$TMM))
}

# apply the function to the normalized dgl objects
smallRNA_seqs <- map2(norm_dgls, list(annot_tbl, annot_tbl), ~function_prep_hist(.x,.y))

# make the dataframes with info regarding expressed gene_types
fc_n <- smallRNA_seqs[["fc"]] %>% 
  dplyr::count(gene_type, sort = T) %>% 
  dplyr::rename("fc_n" = n) 

salmon_n <- smallRNA_seqs[["salmon"]] %>% 
  dplyr::count(gene_type, sort = T) %>% 
  dplyr::rename("salmon_n" = n)

common_n <- smallRNA_seqs[["fc"]] %>% 
    inner_join(smallRNA_seqs[["salmon"]] ) %>% 
    dplyr::count(gene_type, sort = T) %>% 
    dplyr::rename("common_n" = n)
  
unique_FC_n <- smallRNA_seqs[["fc"]] %>% 
    anti_join(smallRNA_seqs[["salmon"]] ) %>% 
    dplyr::count(gene_type, sort = T) %>% 
    dplyr::rename("unique_FC_n" = n)

unique_salmon_n <- smallRNA_seqs[["salmon"]]  %>% 
    anti_join(smallRNA_seqs[["fc"]]) %>% 
    dplyr::count(gene_type, sort = T) %>% 
    dplyr::rename("unique_salmon_n" = n)

stats_gene_types_ids <- fc_n %>% 
  full_join(salmon_n) %>% 
  full_join(common_n) %>%
  full_join(unique_FC_n) %>%
  full_join(unique_salmon_n) %>%
  write_tsv(file.path(dirname(dat_path[1]), "stats_gene_types_ids.txt"))
rm(fc_n, salmon_n, common_n, unique_FC_n, unique_salmon_n)
```
### ii. Make histograms of length

```{r histogram of seq length}
# make a hist 
hist_tbl <- comp_FC_sal %>% 
  bind_rows(.id = "method") %>% 
  pivot_longer(cols = !c(method,sncRNA)) %>% 
  left_join(annot_tbl, by = c("sncRNA" = "gene_id"))
# filter cpm value to keep only the expressed molecules
hist_tbl <- hist_tbl %>%
  filter(value > 0)
pdf(file.path(dirname(dat_path[1]),"length_histogram.pdf"))
hist_tbl$gene_type %>% 
  as_factor() %>% 
  levels() %>% 
  map(~filter(hist_tbl, gene_type == .x) %>%
        filter(!is.na(method),!is.na(name)) %>% 
        ggplot() +
        geom_bar(mapping = aes(x = factor(length_w), fill = method), position = "dodge") +
        facet_wrap(~ name, nrow = 1) +
        scale_x_discrete(name = 'length')+ 
        scale_y_continuous(labels = scales::comma, guide = guide_axis(angle = 45))+
        ggtitle(.x) +
        coord_flip() +
        theme_bw()
      )
dev.off()
```
## 14. Sequence logos

```{r sequences logos}
# sequences logos -----
library(ggseqlogo)

sample_groups <- hist_tbl %>% dplyr::count(name) %>% .$name


pdf(file.path(dirname(dat_path[1]), "piRNA_logos_FC_salmon.pdf"))
#salmon
map(.x = sample_groups, 
  .f = ~hist_tbl %>% 
    filter(gene_type == "piRNA", method == "salmon", name == .x) %>% 
    mutate(seq_RNA = seq_RNA %>% str_sub(1,15)) %>% 
    .$seq_RNA %>% 
    ggseqlogo(method = 'prob', font="roboto_regular") +
    ggtitle(str_glue("Salmon_{.x}")) +
    annotate('rect', xmin = 9.5, xmax = 10.5, 
           ymin = -0.05, ymax = 1.05,
           alpha = .1, col='black', fill='yellow') +
    annotate('rect', xmin = 0.5, xmax = 1.5, 
           ymin = -0.05, ymax = 1.05,
           alpha = .1, col='black', fill='yellow')
  )  
#featureCounts
map(.x = sample_groups, 
  .f = ~hist_tbl %>%
    filter(gene_type == "piRNA", method == "fc", name == .x) %>% 
    mutate(seq_RNA = seq_RNA %>% str_sub(1,15)) %>% 
    .$seq_RNA %>% 
    ggseqlogo(method = 'prob', font="roboto_regular") +
    ggtitle(str_glue("FeatureCounts_{.x}")) +
    annotate('rect', xmin = 9.5, xmax = 10.5, 
           ymin = -0.05, ymax = 1.05,
           alpha = .1, col='black', fill='yellow') +
    annotate('rect', xmin = 0.5, xmax = 1.5, 
           ymin = -0.05, ymax = 1.05,
           alpha = .1, col='black', fill='yellow')
  )
dev.off()

```
## 15. plots and tables regarding piRNAs and spike-ins
Use two different datasets, one for testis, one fore COLO205
### i. COLO205 samples
We slice the filtered primary dataset and we use normalization per each sample, thus only within sample norm.
```{r Dataset COLO205 FC, salmon}
# create a dataset with cpm values for both methods of COLO205 samples
cpm_COLO_norm <- names(filtered_dgls) %>% set_names() %>% 
  map(~filtered_dgls[[.x]] %>% 
        cpm(normalized.lib.sizes = TRUE, log = FALSE, prior.count = 2) %>% 
        as_tibble(rownames = "sncRNA") %>% 
        select(sncRNA, contains("COLO205"))
      ) %>% 
  bind_rows(.id = "method")
```
### ii. Testis samples

```{r Dataset Testis FC, salmon}
# create a dataset with cpm values for both methods of Testis samples
cpm_Testis_norm <- names(filtered_dgls) %>% set_names() %>% 
  map(~filtered_dgls[[.x]] %>% 
        cpm(normalized.lib.sizes = TRUE, log = FALSE, prior.count = 2) %>% 
        as_tibble(rownames = "sncRNA") %>% 
        select(sncRNA, contains("estis"))
      ) %>% 
  bind_rows(.id = "method")
```
### iii. Plot the cpm of spike-ins in COLO205, Testis before and after treatment

```{r barplot of spike ins}
spikes_ins_COLO_plot <- cpm_COLO_norm %>% 
  filter(str_detect(sncRNA,"SS_")) %>% 
  pivot_longer(cols = -c(method, sncRNA)) %>% 
  ggplot(mapping = aes(x = sncRNA, y= value, fill = method)) +
  geom_bar(stat = "identity", position=position_dodge(), width=0.2) +
  scale_x_discrete(name = "piRNA-like ~ spike-ins", 
                   guide = guide_axis(angle = 45)) + 
  scale_y_continuous(name = "Counts per million", 
                     labels = scales::comma, 
                     breaks = scales::pretty_breaks(n = 10)) +
  theme_bw() +
  scale_fill_manual(values=c('#999999','#E69F00')) +
  facet_wrap(~ name, ncol = 3) 

spikes_ins_testis_plot <- cpm_Testis_norm %>% 
  filter(str_detect(sncRNA,"SS_")) %>% 
  pivot_longer(cols = -c(method, sncRNA)) %>% 
  ggplot(mapping = aes(x = sncRNA, y= value, fill = method)) +
  geom_bar(stat = "identity", position=position_dodge(), width=0.2) +
  scale_x_discrete(name = "piRNA-like ~ spike-ins", 
                   guide = guide_axis(angle = 45)) + 
  scale_y_continuous(name = "Counts per million", 
                     labels = scales::comma, 
                     breaks = scales::pretty_breaks(n = 10)) +
  theme_bw() +
  scale_fill_manual(values=c('#999999','#E69F00')) +
  facet_wrap(~ name, ncol = 3) 

zoom_spikes_ins_COLO_plot <- spikes_ins_COLO_plot + coord_cartesian(ylim = c(0, 5000)) 
zoom_spikes_ins_testis_plot <- spikes_ins_testis_plot + coord_cartesian(ylim = c(0, 5000)) 

pdf(file.path(dirname(dat_path[1]), "spike_ins_treat_FC_salmon.pdf"))
spikes_ins_COLO_plot
zoom_spikes_ins_COLO_plot
spikes_ins_testis_plot
zoom_spikes_ins_testis_plot
dev.off()

```
### iv. BoxPlot of piRNAs in COLO205 and Testis before and after treatment

```{r boxplot of piRNAs}
# function for summarizing stats
my_quantile <- function(x) {
  tibble(
    min = min(x, na.rm = TRUE),
    q1 = quantile(x, 0.25, na.rm = TRUE), 
    mean = mean(x, na.rm = TRUE),
    median = median(x, na.rm = TRUE),
    q3 = quantile(x, 0.75, na.rm = TRUE),
    max = max(x, na.rm = TRUE),
    sd = sd(x, na.rm = TRUE))
}

piRNAs_COLO_testis <- full_join(cpm_COLO_norm , cpm_Testis_norm, 
                             by = c("method","sncRNA")) %>% 
  left_join(complete_biotypes_seqs) %>% # found in 15. paragraph
  filter(str_detect(gene_type,"piRNA")) %>% 
  select(-c(seq_RNA, source,GENCODE_annot:sRNA_id2)) %>% 
  pivot_longer(cols = -c(method, sncRNA,gene_type))

# check the stats
piRNAs_COLO_testis%>% 
  group_by(name) %>% 
  summarise(my_quantile(value))
mutate(name = factor(name, levels = c("Non_treated_COLO205_1",
                                        "Non_treated_COLO205_2",
                                        "Non_treated_COLO205_3",
                                        "Treated_COLO205_1",
                                        "Treated_COLO205_2",
                                        "Treated_COLO205_3",
                                        "Non_treated_Testis_1",
                                        "Treated_testis_1"))) %>% 

piRNAs_plot <- piRNAs_COLO_testis %>% 
  filter(value < 100) %>% 
  ggplot(mapping = aes(x = gene_type, y= value, fill = method)) +
  geom_boxplot(outlier.colour="black", outlier.shape=16, outlier.alpha = 0.1, 
             outlier.size=1, notch=TRUE, width = 0.5)+
  scale_x_discrete(name = "samples", guide = guide_axis(angle = 45)) +
  scale_y_continuous(name = "Counts per million", 
                     labels = scales::comma, 
                     breaks = scales::pretty_breaks(n = 10)) +
  theme_bw() +
  scale_fill_manual(values=c('#999999','#E69F00')) +
  facet_wrap(~name, ncol = 3) 

pdf(file.path(dirname(dat_path[1]), "piRNAs_bxplot_Testis_COLO205_treat_FC_salmon.pdf"))
piRNAs_plot
dev.off()
```
## 16.  Dilutions of spike-ins in various samples and between treated non treated
### i. Spike-ins for dilutions and treated, non-treated
make the tables with information per read, and sncRNA aligned

```{bash fastq reads spike_ins}
ANALYSIS_FOLDER="my_data/Datasets_analysis/Testis_COLO205"

## find length of reads from STAR - featureCounts
for file in $ANALYSIS_FOLDER/star/*featureCounts.bam; 
do
where_to_save=`dirname ${file}`; 
regex=`basename ${file}`; 
samp="${regex%%.sortedByCoord.out.bam.featureCounts.bam}";
echo "Processing sample ${samp} start: $(date) and saving in: ${where_to_save}/${samp}_hist.txt";  
samtools view -@ 6 ${file} | awk 'BEGIN{FS=OFS="\t"}{print length($10),$18}'| sed 's/XT:Z://g'  | sort -k2,2 | uniq -c | sed -e 's/^ *//g'| sed 's/ /\t/g' > ${where_to_save}/${samp}_hist.txt;
echo "end:$(date)"; 
done

## find length of reads from salmon
for file in $ANALYSIS_FOLDER/quants/*.bam;  
do 
where_to_save=`dirname ${file}`;  
regex=`basename ${file}`;  
samp="${regex%%.trimmed*}";  
echo "Processing sample ${samp} start: $(date) and saving in: ${where_to_save}/${samp}_hist_allRNA.txt"; 
samtools view  -@ 4 ${file} | awk 'BEGIN{FS=OFS="\t"}{print $1,length($10),$3}'| sort -k1,1 | bedtools groupby -g 1 -c 2,3 -o first,distinct -delim "," | cut -f2,3 | sort -k2,2 | uniq -c | sed -e 's/^ *//g'| sed 's/ /\t/g' > ${where_to_save}/${samp}_hist_allRNA.txt; 
echo "end:$(date)"; 
done
```
### ii. trimmed fastq reads of the samples

```{bash}

for file in  "${ANALYSIS_FOLDER}"/downloaded_samples/*.trimmed.fastq.gz; 
do 
samp=`basename ${file}`; 
echo "Processing sample ${samp} start: $(date)"; 
numb_reads=`zcat ${file} | awk '{s++}END{print s/4}' -`; 
echo "${samp}    ${numb_reads}" | tee -a  "${ANALYSIS_FOLDER}/trimmed_reads_v2.txt";
echo "end:$(date)";
done
```

### iii. Spike-ins for dilutions and treated\non-treated

```{r tables with reads info}
targets_file$group
# we will keep the only the samples that have spike-ins
targets_file_spike <- targets_file %>% 
  filter(!run_accession %in% c("ERR4846431", "ERR4846432", "ERR4846433")) %>% 
  select(run_accession, sample_name)
# featurecounts ----
FC_files <- list.files(path = file.path(my_basename, "star"),
                         pattern = "_Aligned_hist.txt", recursive = TRUE, 
                         full.names = TRUE) %>% 
  set_names(nm = basename(.) %>% str_remove("_.+"))

## keep only the related files
FC_files <- FC_files[names(FC_files) %in% as.character(targets_file_spike$run_accession)]


hist_files_fc <-  FC_files %>% 
  vroom::vroom(id = "file", # import them with vroom
               col_names = c("read_count", "read_length", "smallRNA")) %>% 
    # add information regarding Not_assigned reads and clean filenames
  mutate(file = basename(file) %>% str_remove_all(".bam|_Ali.+"),
         smallRNA = if_else(condition = is.na(smallRNA),
                            true = "Not_assigned",
                            false = smallRNA),
         method = "fc") %>% 
  filter(str_detect(smallRNA, "SS"))

# salmon ----
salmon_files <- list.files(path = file.path(my_basename, "quants"),
                         pattern = "_hist.+", recursive = TRUE, 
                         full.names = TRUE) %>% 
  set_names(nm = basename(.) %>% str_remove(".bam.+"))

## keep only the related files
salmon_files <- salmon_files[names(salmon_files) %in% as.character(targets_file_spike$run_accession)]


hist_files_salmon <- salmon_files %>% 
    vroom::vroom(id = "file", # import them with vroom
               col_names = c("read_count", "read_length", "smallRNA")) %>% 
    # add information regarding multimapping reads and clean filenames
  mutate(file = basename(file) %>% str_remove_all(".bam|_hist.+"),
         method = "salmon")%>% 
  filter(str_detect(smallRNA, "SS"))
  
# make one object with both methods --------
hist_all_RNA <- bind_rows(hist_files_salmon, hist_files_fc) %>% 
  mutate(Alignment = case_when(
           smallRNA == "Not_assigned" ~ "Not_assigned",
           str_detect(smallRNA, ",") ~ "Multimapped" ,
           TRUE ~ "Unique" )) %>% 
  left_join(targets_file_spike ,by = c("file" = "run_accession"))

# summarize the reads per sample, per method, per spike-in-------
hist_all_RNA %>%   
  group_by(file, sample_name, method, smallRNA) %>% 
  summarise(reads_sum = sum(read_count)) %>% 
  write_tsv(file.path(dirname(dat_path[1]),"spike_in_reads_summary.txt"))
```

